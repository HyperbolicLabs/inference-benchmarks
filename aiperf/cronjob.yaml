apiVersion: batch/v1
kind: CronJob
metadata:
  name: aiperf-benchmark
  namespace: inference-benchmark
  labels:
    app: aiperf
    component: benchmark
spec:
  # Run every 9 minutes with 8-minute benchmarks for continuous load
  # This ensures no gaps while preventing overlap (1 minute buffer)
  schedule: "*/9 * * * *"
  # Prevent multiple jobs from running simultaneously
  # If a job is still running when the next schedule time arrives, skip it
  concurrencyPolicy: Forbid
  # Keep only recent job history to avoid resource accumulation
  # 5 successful jobs = ~50 minutes of history
  # 3 failed jobs = enough to debug issues
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: aiperf
            component: benchmark
        spec:
          restartPolicy: OnFailure
          imagePullSecrets:
          - name: ghcr-image-pull-secret
          containers:
          - name: aiperf
            # AIPerf benchmarking image from GitHub Container Registry
            # Build and push with: cd scripts/aiperf && make build-push
            image: ghcr.io/hyperboliclabs/aiperf:latest
            imagePullPolicy: Always
            command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "=== Running AIPerf Benchmark ==="
              python3 /scripts/benchmark.py
              
              echo "=== Benchmark Complete ==="
              ls -lh /tmp/results/ || echo "No results directory"
            env:
            - name: MODEL_NAME
              value: "Qwen/Qwen3-VL-32B-Thinking"
            - name: ENDPOINT_URL
              value: "https://inference.hyperbolic.ai"
            - name: ENDPOINT_TYPE
              value: "chat"
            # Cloudflare Access credentials (required for authentication)
            # Update these values with your actual Cloudflare Access service token credentials
            - name: CF_ACCESS_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: cloudflare-access-credentials
                  key: client-id
                  optional: true
            - name: CF_ACCESS_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: cloudflare-access-credentials
                  key: client-secret
                  optional: true
            # Concurrency: Reduced to 10 to reduce number of workers and avoid PROFILE_START timeout
            # Fewer workers = fewer services that need to respond to PROFILE_START command
            # This helps avoid timeout issues where workers don't respond to PROFILE_START
            - name: CONCURRENCY
              value: "10"
            # Use duration-based benchmarking (8 minutes) for sustained load
            # With 10-minute schedule, this creates 2-minute overlaps for continuous load
            - name: BENCHMARK_DURATION
              value: "480"
            - name: BENCHMARK_GRACE_PERIOD
              value: "30"
            # Request timeout: 60 seconds per request (prevents hanging)
            - name: REQUEST_TIMEOUT
              value: "60"
            # Output token limit: Mean of 50 tokens per response for consistent benchmarking
            # This prevents unbounded responses and makes results more predictable
            - name: OUTPUT_TOKENS_MEAN
              value: "50"
            # Keep request_count as a safety limit (will be ignored if benchmark_duration is set)
            - name: REQUEST_COUNT
              value: "10000"
            - name: STREAMING
              value: "true"
            - name: OUTPUT_DIR
              value: "/tmp/results"
            # Environment variables to disable TUI in non-interactive Kubernetes environment
            - name: TERM
              value: "dumb"
            - name: CI
              value: "true"
            - name: NO_COLOR
              value: "1"
            - name: PYTHONUNBUFFERED
              value: "1"
            # AIPerf timeout configuration to prevent timeout errors during service startup
            # These timeouts control how long AIPerf waits for services to respond
            # Increased values help in Kubernetes environments with resource constraints
            - name: AIPERF_SERVICE_PROFILE_CONFIGURE_TIMEOUT
              value: "600.0"  # 10 minutes for configuration (default: 300s)
            - name: AIPERF_SERVICE_PROFILE_START_TIMEOUT
              value: "300.0"  # 5 minutes for start profiling (default: 60s, increased for Kubernetes)
            - name: AIPERF_DATASET_CONFIGURATION_TIMEOUT
              value: "600.0"  # 10 minutes for dataset config (default: 300s)
            # Datadog API key for metrics export (optional)
            - name: DD_API_KEY
              valueFrom:
                secretKeyRef:
                  name: datadog-api-key
                  key: api-key
                  optional: true
            volumeMounts:
            - name: results
              mountPath: /tmp/results
            resources:
              requests:
                memory: "2Gi"      # Increased: AIPerf needs more memory for processing
                cpu: "200m"        # Reduced: Mostly waiting for HTTP responses
              limits:
                memory: "4Gi"      # Increased: More headroom for parsing and metrics
                cpu: "1000m"       # Reduced: Burst capacity for metric processing
          volumes:
          - name: results
            # Use emptyDir to avoid NFS mount issues
            # Results are ephemeral but benchmark metrics go to Datadog
            emptyDir: {}
            # Optional: Use PVC for persistent results
            # persistentVolumeClaim:
            #   claimName: aiperf-results
